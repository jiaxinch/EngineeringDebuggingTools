{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swetabehera04/Horse_Human_Classifer_using_CNN/blob/master/Horse_Human_Classifier_using_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSIrisJO1yMY",
        "colab_type": "text"
      },
      "source": [
        "## Scratch ResNet Image Classification\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuKYElmf7-38",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ec5e834f-6ad5-46de-eb0e-2531979e1648"
      },
      "source": [
        "# !pip install tensorflow==2.0.0\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.layers import *\n",
        "import six\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.python.keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from tensorflow.python.keras.layers import AveragePooling2D, Input, Flatten\n",
        "from tensorflow.python.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.python.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras.regularizers import l2\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.keras.models import Model\n",
        "from tensorflow.python.keras.layers import *\n",
        "from tensorflow.python.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.keras.utils.conv_utils import convert_kernel\n",
        "from tensorflow.python.util import nest\n",
        "from tensorflow.python.util import object_identity\n",
        "from tensorflow.python.util.tf_export import keras_export\n",
        "import zipfile\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMY7K7M5SwwZ",
        "colab_type": "code",
        "outputId": "50a1a10f-16a5-4274-8777-0c54ca928144",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "class DefaultConfig():\n",
        "\n",
        "    try:\n",
        "        model_name = sys.argv[1]\n",
        "    except:\n",
        "        print(\"use default model LeNet, see config.py\")\n",
        "        model_name = \"LeNet\"\n",
        "\n",
        "    train_data_path = './dataset/train/'\n",
        "    test_data_path = './dataset/test/'\n",
        "    checkpoints = './checkpoints/'\n",
        "\n",
        "    if model_name == 'InceptionV3':\n",
        "        normal_size = 75#minSize\n",
        "    elif model_name == 'Xception':\n",
        "        normal_size = 71#minSize\n",
        "    else:\n",
        "        normal_size = 28\n",
        "    # normal_size = 48\n",
        "    epochs = 1\n",
        "    batch_size = 2\n",
        "    classNumber = 10 # see dataset/tri\n",
        "    channles = 1 # or 3 or 1\n",
        "    lr = 0.00001\n",
        "    lr_reduce_patience = 5  # 需要降低学习率的训练步长\n",
        "    early_stop_patience = 11  # 提前终止训练的步长\n",
        "\n",
        "    data_augmentation = False\n",
        "    monitor = 'val_loss'\n",
        "    cut = False\n",
        "    rat = 0.1 #if cut,img[slice(h*self.rat,h-h*self.rat),slice(w*self.rat,w-w*self.rat)]\n",
        "config=DefaultConfig()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "use default model LeNet, see config.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9F8BvjkVSKuw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "4dce9d66-ab40-4f97-d894-c5b65d4a0f69"
      },
      "source": [
        "class MODEL(object):\n",
        "\n",
        "    def __init__(self,config):\n",
        "        self.config = config\n",
        "\n",
        "    def input_shape_define(self):\n",
        "        return  (self.config.normal_size, self.config.normal_size, self.config.channles)\n",
        "\n",
        "    def covn_block(self,model,kenal_number,kenal_size,padding,activation):\n",
        "        model.add(Convolution2D(kenal_number,kenal_size,padding=padding,activation=activation))\n",
        "        return model\n",
        "\n",
        "    def max_pooling_type(self,model,kenal_size,strides):\n",
        "        model.add(MaxPooling2D(pool_size=kenal_size,strides=strides))\n",
        "        return model\n",
        "\n",
        "    def mnist_net(self):\n",
        "        model = Sequential()\n",
        "        input_shape = (self.config.normal_size, self.config.normal_size, self.config.channles)\n",
        "        model.add(Convolution2D(96,(3,3),input_shape=input_shape,padding='same',activation='relu',kernel_initializer='uniform'))\n",
        "        model.add(Convolution2D(128,(3,3),padding='same',activation='relu'))\n",
        "        model.add(Convolution2D(128,(1,1),padding='same',activation='relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "        model.add(Convolution2D(256,(3,3),padding='same',activation='relu'))\n",
        "        model.add(Convolution2D(256,(1,1),padding='same',activation='relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "        model.add(Convolution2D(512, (3, 3), padding='same', activation='relu'))\n",
        "        model.add(Convolution2D(512, (3, 3), padding='same', activation='relu'))\n",
        "        model.add(Convolution2D(256, (1, 1), padding='same', activation='relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "        model.add(Convolution2D(512, (3, 3), padding='same', activation='relu'))\n",
        "        model.add(Convolution2D(512, (3, 3), padding='same', activation='relu'))\n",
        "        model.add(Convolution2D(256, (1, 1), padding='same', activation='relu'))\n",
        "        # model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096,activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2048, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(self.config.classNumber,activation='softmax'))\n",
        "        return model\n",
        "\n",
        "    #VGG16\n",
        "    def TSL16(self):\n",
        "        model = Sequential()\n",
        "        input_shape = (self.config.normal_size, self.config.normal_size, self.config.channles)\n",
        "        model.add(Convolution2D(64,kernel_size=(3,3),input_shape=input_shape,padding='same',activation='relu'))\n",
        "        model.add(Convolution2D(64,kernel_size=(3,3),padding='same',activation='relu'))\n",
        "        model = self.max_pooling_type(model,kenal_size=(2,2),strides=(2,2))\n",
        "        for i in range(2):\n",
        "            model = self.covn_block(model, kenal_number=128, kenal_size=(3, 3), padding='same', activation='relu')\n",
        "\n",
        "        model = self.max_pooling_type(model,kenal_size = (2,2),strides=(2,2))\n",
        "        for i in range(3):\n",
        "            model = self.covn_block(model,kenal_number=128,  kenal_size=(3,3),  padding='same',activation='relu')\n",
        "\n",
        "        model = self.max_pooling_type(model,kenal_size=(2,2),strides=(2,2))\n",
        "        for i in range(3):\n",
        "            model = self.covn_block(model,kenal_number=512,kenal_size=(3,3),padding='same',activation='relu')\n",
        "\n",
        "        model = self.max_pooling_type(model,kenal_size=(2,2),strides=(2,2))\n",
        "        for i in range(3):\n",
        "            model = self.covn_block(model,kenal_number=512,kenal_size=(3,3),padding='same',activation='relu')\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096,activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(1024,activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(self.config.classNumber,activation='softmax'))\n",
        "        return model\n",
        "\n",
        "\n",
        "    # AlexNet\n",
        "    def AlexNet(self):\n",
        "        model = Sequential()\n",
        "        # input_shape = (64,64, self.config.channles)\n",
        "        input_shape = (224, 224, 1)\n",
        "        model.add(Convolution2D(96, (11, 11), input_shape=input_shape,strides=(4, 4),  padding='valid',activation='relu', kernel_initializer='uniform'))\n",
        "        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))#26*26\n",
        "        model.add(Convolution2D(256, (5, 5), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "        model.add(Convolution2D(384, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "        model.add(Convolution2D(384, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "        model.add(Convolution2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(self.config.classNumber, activation='softmax'))\n",
        "        # model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "        return model\n",
        "\n",
        "    def VGG16(self):\n",
        "        model = Sequential()\n",
        "        input_shape= (self.config.normal_size, self.config.normal_size, self.config.channles)\n",
        "        model.add(Convolution2D(64,(3,3),input_shape=input_shape,activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(64,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(128,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(128,(3,3),activation='relu',padding='same'))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "        model.add(Convolution2D(256,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(256,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(256,(3,3),activation='relu',padding='same'))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "        model.add(Convolution2D(512,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(512,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(512,(3,3),activation='relu',padding='same'))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "        model.add(Convolution2D(512,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(512,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(512,(3,3),activation='relu',padding='same'))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096,activation='relu'))\n",
        "        model.add(Dense(4096,activation='relu'))\n",
        "        model.add(Dense(self.config.classNumber,activation='softmax'))\n",
        "        return model\n",
        "\n",
        "    def VGG19(self):\n",
        "        model = Sequential()\n",
        "        input_shape= (self.config.normal_size, self.config.normal_size, self.config.channles)\n",
        "        model.add(Convolution2D(64,(3,3),input_shape=input_shape,activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(64,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(128,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(128,(3,3),activation='relu',padding='same'))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "        model.add(Convolution2D(256,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(256,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(256,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(256,(3,3),activation='relu',padding='same'))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "        model.add(Convolution2D(512,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(512,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(512,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(512,(3,3),activation='relu',padding='same'))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "        model.add(Convolution2D(512,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(512,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(512,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(512,(3,3),activation='relu',padding='same'))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096,activation='relu'))\n",
        "        model.add(Dense(4096,activation='relu'))\n",
        "        model.add(Dense(self.config.classNumber,activation='softmax'))\n",
        "        return model\n",
        "\n",
        "    #LeNet\n",
        "    def LeNet(self):\n",
        "        # initialize the model\n",
        "        model = Sequential()\n",
        "        inputShape = (self.config.normal_size, self.config.normal_size, self.config.channles)\n",
        "        model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=inputShape))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "        # second set of CONV => RELU => POOL layers\n",
        "        model.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "        # first (and only) set of FC => RELU layers\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(500))\n",
        "        model.add(Activation(\"relu\"))\n",
        "\n",
        "        # softmax classifier\n",
        "        model.add(Dense(self.config.classNumber))\n",
        "        model.add(Activation(\"softmax\"))\n",
        "        # model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "        # return the constructed network architecture\n",
        "        return model\n",
        "\n",
        "    #ZF_Net,8 layers\n",
        "    def ZF_Net(self):\n",
        "        model = Sequential()\n",
        "        model.add(\n",
        "            Conv2D(96, (7, 7), strides=(2, 2),\n",
        "                   input_shape=(224, 224,1),\n",
        "                   padding='valid',\n",
        "                   activation='relu',\n",
        "                   kernel_initializer='uniform'))\n",
        "        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "        model.add(Conv2D(256, (5, 5), strides=(2, 2), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "        model.add(Conv2D(384, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "        model.add(Conv2D(384, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "        model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(self.config.classNumber, activation='softmax'))\n",
        "        # model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "        return model\n",
        "\n",
        "config=DefaultConfig()\n",
        "mdbd = MODEL(config)\n",
        "lenet = mdbd.LeNet()\n",
        "\n",
        "vgg16 = mdbd.VGG16()\n",
        "vgg19 = mdbd.VGG19()\n",
        "zfnet = mdbd.ZF_Net()\n",
        "alexnet = mdbd.AlexNet()\n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrmmFWtiYILy",
        "colab_type": "code",
        "outputId": "b23baa3d-195c-4be7-bb23-64045ba45ca3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alexnet(224x224x1)': Dimension(204608),\n",
              " 'lenet(28x28x1)': Dimension(7390),\n",
              " 'vgg16(28x28x1)': Dimension(266176),\n",
              " 'vgg19(28x28x1)': Dimension(308416),\n",
              " 'zfnet(224x224x1)': Dimension(431936)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0fSagni-rMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResnetBuilder(object):\n",
        "    # @staticmethod\n",
        "    def build(self, block_fn, repetitions):\n",
        "        \"\"\"Builds a custom ResNet like architecture.\n",
        "        Args:\n",
        "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
        "            num_outputs: The number of outputs at final softmax layer\n",
        "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n",
        "                The original paper used basic_block for layers < 50\n",
        "            repetitions: Number of repetitions of various block units.\n",
        "                At each block unit, the number of filters are doubled and the input size is halved\n",
        "        Returns:\n",
        "            The keras `Model`.\n",
        "        \"\"\"\n",
        "\n",
        "        input_shape = (28,28,1)\n",
        "        num_outputs = 10\n",
        "        self._handle_dim_ordering()\n",
        "        block_fn = self._get_block(block_fn)\n",
        "\n",
        "        input = Input(shape=input_shape)\n",
        "        conv1 = self._conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(input)\n",
        "        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
        "\n",
        "        block = pool1\n",
        "        filters = 64\n",
        "        for i, r in enumerate(repetitions):\n",
        "            block = self._residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
        "            filters *= 2\n",
        "\n",
        "        # Last activation\n",
        "        block = self._bn_relu(block)\n",
        "\n",
        "        # Classifier block\n",
        "        block_shape = K.int_shape(block)\n",
        "        pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]),\n",
        "                                 strides=(1, 1))(block)\n",
        "\n",
        "        flatten1 = Flatten()(pool2)\n",
        "        dense = Dense(units=num_outputs,\n",
        "                      activation=\"softmax\")(flatten1)\n",
        "\n",
        "        model = Model(inputs=input, outputs=dense)\n",
        "        # model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "        return model\n",
        "\n",
        "    # @staticmethod\n",
        "    def build_custom_resnet(self,params):\n",
        "        return self.build(self.basic_block, [params[0], params[1], params[2], params[3]])\n",
        "        \n",
        "    # @staticmethod\n",
        "    def build_resnet18(self):\n",
        "        return self.build(self.basic_block, [2, 2, 2, 2])\n",
        "\n",
        "    # @staticmethod\n",
        "    def build_resnet34(self):\n",
        "        return self.build( self.basic_block, [3, 4, 6, 3])\n",
        "\n",
        "    # @staticmethod\n",
        "    def build_resnet50(self):\n",
        "        return self.build( self.bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "    # @staticmethod\n",
        "    def build_resnet101(self):\n",
        "        return self.build(self.bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "    # @staticmethod\n",
        "    def build_resnet152(self):\n",
        "        return self.build( self.bottleneck, [3, 8, 36, 3])\n",
        "\n",
        "    def _bn_relu(self,input):\n",
        "        \"\"\"Helper to build a BN -> relu block\n",
        "        \"\"\"\n",
        "        norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
        "        return Activation(\"relu\")(norm)\n",
        "\n",
        "    def _conv_bn_relu(self,**conv_params):\n",
        "        \"\"\"Helper to build a conv -> BN -> relu block\n",
        "        \"\"\"\n",
        "        filters = conv_params[\"filters\"]\n",
        "        kernel_size = conv_params[\"kernel_size\"]\n",
        "        strides = conv_params.setdefault(\"strides\", (1, 1))\n",
        "        kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
        "        padding = conv_params.setdefault(\"padding\", \"same\")\n",
        "        kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
        "\n",
        "        def f(input):\n",
        "            conv = Conv2D(filters=filters, kernel_size=kernel_size,\n",
        "                          strides=strides, padding=padding,\n",
        "                          kernel_initializer=kernel_initializer,\n",
        "                          kernel_regularizer=kernel_regularizer)(input)\n",
        "            return self._bn_relu(conv)\n",
        "\n",
        "        return f\n",
        "\n",
        "\n",
        "    def _bn_relu_conv(self,**conv_params):\n",
        "        \"\"\"Helper to build a BN -> relu -> conv block.\n",
        "        This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "        \"\"\"\n",
        "        filters = conv_params[\"filters\"]\n",
        "        kernel_size = conv_params[\"kernel_size\"]\n",
        "        strides = conv_params.setdefault(\"strides\", (1, 1))\n",
        "        kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
        "        padding = conv_params.setdefault(\"padding\", \"same\")\n",
        "        kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
        "\n",
        "        def f(input):\n",
        "            activation = self._bn_relu(input)\n",
        "            return Conv2D(filters=filters, kernel_size=kernel_size,\n",
        "                          strides=strides, padding=padding,\n",
        "                          kernel_initializer=kernel_initializer,\n",
        "                          kernel_regularizer=kernel_regularizer)(activation)\n",
        "\n",
        "        return f\n",
        "\n",
        "\n",
        "    def _shortcut(self,input, residual):\n",
        "        \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n",
        "        \"\"\"\n",
        "        # Expand channles of shortcut to match residual.\n",
        "        # Stride appropriately to match residual (width, height)\n",
        "        # Should be int if network architecture is correctly configured.\n",
        "        input_shape = K.int_shape(input)\n",
        "        residual_shape = K.int_shape(residual)\n",
        "        stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
        "        stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
        "        equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
        "\n",
        "        shortcut = input\n",
        "        # 1 X 1 conv if shape is different. Else identity.\n",
        "        if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
        "            shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n",
        "                              kernel_size=(1, 1),\n",
        "                              strides=(stride_width, stride_height),\n",
        "                              padding=\"valid\",\n",
        "                              kernel_initializer=\"he_normal\",\n",
        "                              kernel_regularizer=l2(0.0001))(input)\n",
        "\n",
        "        return add([shortcut, residual])\n",
        "\n",
        "\n",
        "    def _residual_block(self,block_function, filters, repetitions, is_first_layer=False):\n",
        "        \"\"\"Builds a residual block with repeating bottleneck blocks.\n",
        "        \"\"\"\n",
        "        def f(input):\n",
        "            for i in range(repetitions):\n",
        "                init_strides = (1, 1)\n",
        "                if i == 0 and not is_first_layer:\n",
        "                    init_strides = (2, 2)\n",
        "                input = block_function(filters=filters, init_strides=init_strides,\n",
        "                                       is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
        "            return input\n",
        "\n",
        "        return f\n",
        "\n",
        "\n",
        "    def basic_block(self,filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
        "        \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
        "        Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "        \"\"\"\n",
        "        def f(input):\n",
        "\n",
        "            if is_first_block_of_first_layer:\n",
        "                # don't repeat bn->relu since we just did bn->relu->maxpool\n",
        "                conv1 = Conv2D(filters=filters, kernel_size=(3, 3),\n",
        "                               strides=init_strides,\n",
        "                               padding=\"same\",\n",
        "                               kernel_initializer=\"he_normal\",\n",
        "                               kernel_regularizer=l2(1e-4))(input)\n",
        "            else:\n",
        "                conv1 = self._bn_relu_conv(filters=filters, kernel_size=(3, 3),\n",
        "                                      strides=init_strides)(input)\n",
        "\n",
        "            residual = self._bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n",
        "            return self._shortcut(input, residual)\n",
        "\n",
        "        return f\n",
        "\n",
        "\n",
        "    def bottleneck(self,filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
        "        \"\"\"Bottleneck architecture for > 34 layer resnet.\n",
        "        Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "        Returns:\n",
        "            A final conv layer of filters * 4\n",
        "        \"\"\"\n",
        "        def f(input):\n",
        "\n",
        "            if is_first_block_of_first_layer:\n",
        "                # don't repeat bn->relu since we just did bn->relu->maxpool\n",
        "                conv_1_1 = Conv2D(filters=filters, kernel_size=(1, 1),\n",
        "                                  strides=init_strides,\n",
        "                                  padding=\"same\",\n",
        "                                  kernel_initializer=\"he_normal\",\n",
        "                                  kernel_regularizer=l2(1e-4))(input)\n",
        "            else:\n",
        "                conv_1_1 = self._bn_relu_conv(filters=filters, kernel_size=(1, 1),\n",
        "                                         strides=init_strides)(input)\n",
        "\n",
        "            conv_3_3 = self._bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv_1_1)\n",
        "            residual = self._bn_relu_conv(filters=filters * 4, kernel_size=(1, 1))(conv_3_3)\n",
        "            return self._shortcut(input, residual)\n",
        "\n",
        "        return f\n",
        "\n",
        "    def _handle_dim_ordering(self):\n",
        "        global ROW_AXIS\n",
        "        global COL_AXIS\n",
        "        global CHANNEL_AXIS\n",
        "    \n",
        "        ROW_AXIS = 1\n",
        "        COL_AXIS = 2\n",
        "        CHANNEL_AXIS = 3\n",
        "      \n",
        "\n",
        "    def _get_block(self,identifier):\n",
        "        if isinstance(identifier, six.string_types):\n",
        "            res = globals().get(identifier)\n",
        "            if not res:\n",
        "                raise ValueError('Invalid {}'.format(identifier))\n",
        "            return res\n",
        "        return identifier\n",
        "resnetbd = ResnetBuilder()\n",
        "resnet2232 = resnetbd.build_custom_resnet([2,2,3,2])\n",
        "resnet1232 = resnetbd.build_custom_resnet([1,2,3,2])\n",
        "resnet1222 = resnetbd.build_custom_resnet([1,2,2,2])\n",
        "resnet1212 = resnetbd.build_custom_resnet([1,2,1,2])\n",
        "resnet2111 = resnetbd.build_custom_resnet([2,1,1,1])\n",
        "resnet1112 = resnetbd.build_custom_resnet([1,1,1,2])\n",
        "resnet1111 = resnetbd.build_custom_resnet([1,1,1,1])\n",
        "resnet3232 = resnetbd.build_custom_resnet([3,2,3,2])\n",
        "resnet3463 = resnetbd.build_custom_resnet([3,4,6,3])\n",
        "resnet2222 = resnetbd.build_custom_resnet([2,2,2,2]) #18\n",
        "resnet50 = resnetbd.build_resnet50() #3463\n",
        "resnet152 =resnetbd.build_resnet152()#3,8,36,3\n",
        "resnet101 =resnetbd.build_resnet101()#3,8,36,3\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h85DpxGC6MHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def capacity_estimate_v2(model):\n",
        "  capacity_dic = {}\n",
        "  capacity_list = []\n",
        "  output_dic={}\n",
        "  \n",
        "  MAX_VALUE=10000000\n",
        "  # pre_capcity=MAX_VALUE\n",
        "  bottle_neck_capacity = MAX_VALUE\n",
        "  total_capacity = 0\n",
        "  for layer in model.layers:\n",
        "    connections=[]\n",
        "    for node in layer._inbound_nodes:\n",
        "      for inbound_layer, node_index, tensor_index, _ in node.iterate_inbound():\n",
        "        connections.append(inbound_layer.name)\n",
        "      \n",
        "    capacity=0  \n",
        "    if len(connections)!=0:\n",
        "      for layer_name in connections:\n",
        "        if layer_name.find('input')!=-1:\n",
        "          capacity = model.input.shape[1]*model.input.shape[2]*model.input.shape[3]  \n",
        "        else:\n",
        "          capacity = max(output_dic[layer_name],capacity)\n",
        "    else:\n",
        "        capacity = MAX_VALUE\n",
        "    \n",
        "    capacity = min(capacity,layer.count_params())\n",
        "    capacity_dic[layer.name] = min(bottle_neck_capacity,capacity)\n",
        "    capacity_list.append((layer.name,min(bottle_neck_capacity,capacity)))\n",
        "\n",
        "    # if capacity!=0:\n",
        "    #   capacity_dic[layer.name] = min(pre_capcity,capacity)\n",
        "    #   capacity_list.append((layer.name,min(pre_capcity,capacity)))\n",
        "    #   pre_capcity=min(pre_capcity,capacity)\n",
        "    # else:\n",
        "    #   capacity_dic[layer.name] = capacity\n",
        "    #   capacity_list.append((layer.name,capacity))\n",
        "    output_bits = 0\n",
        "    output_shape = layer.output.shape\n",
        "    \n",
        "    if len(output_shape) == 2:\n",
        "      output_bits = output_shape[1]\n",
        "    else:\n",
        "      output_bits = output_shape[1]*output_shape[2]*output_shape[3]\n",
        "\n",
        "    bottle_neck_capacity = min(output_bits,bottle_neck_capacity)\n",
        "\n",
        "    output_dic[layer.name] = bottle_neck_capacity\n",
        "    \n",
        "    total_capacity += capacity\n",
        "\n",
        "  return total_capacity,capacity_list\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKvFYMS8qO9W",
        "colab_type": "code",
        "outputId": "5c7d29c6-7e56-4988-cd88-57913c3c89c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "cpdic={}\n",
        "\n",
        "cpdic['2232']=capacity_estimate_v2(resnet2232)[0]\n",
        "cpdic['1232']=capacity_estimate_v2(resnet1232)[0]\n",
        "cpdic['1222']=capacity_estimate_v2(resnet1222)[0]\n",
        "cpdic['1212']=capacity_estimate_v2(resnet1212)[0]\n",
        "cpdic['2111']=capacity_estimate_v2(resnet2111)[0]\n",
        "cpdic['1112']=capacity_estimate_v2(resnet1112)[0]\n",
        "cpdic['1111']=capacity_estimate_v2(resnet1111)[0]\n",
        "cpdic['3232']=capacity_estimate_v2(resnet3232)[0]\n",
        "cpdic['3463']=capacity_estimate_v2(resnet3463)[0]\n",
        "cpdic['2222']=capacity_estimate_v2(resnet2222)[0]\n",
        "cpdic['3463(50)']=capacity_estimate_v2(resnet50)[0]\n",
        "cpdic['3463(50)']=capacity_estimate_v2(resnet50)[0]\n",
        "cpdic['resnet151']=capacity_estimate_v2(resnet152)[0]\n",
        "cpdic['resnet101']=capacity_estimate_v2(resnet101)[0]\n",
        "cpdic"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1111': Dimension(14032),\n",
              " '1112': Dimension(16080),\n",
              " '1212': Dimension(18672),\n",
              " '1222': Dimension(21808),\n",
              " '1232': Dimension(24944),\n",
              " '2111': Dimension(16112),\n",
              " '2222': Dimension(23888),\n",
              " '2232': Dimension(27024),\n",
              " '3232': Dimension(29104),\n",
              " '3463': Dimension(45744),\n",
              " '3463(50)': Dimension(69984),\n",
              " 'resnet101': Dimension(149952),\n",
              " 'resnet151': Dimension(227744)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDdsgcyHF52D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "f53e78de-a539-4cbb-8643-487b53d6a5f7"
      },
      "source": [
        "othernet={}\n",
        "othernet['lenet(28x28x1)']=capacity_estimate_v2(lenet)[0]\n",
        "othernet['vgg16(28x28x1)']=capacity_estimate_v2(vgg16)[0]\n",
        "othernet['vgg19(28x28x1)']=capacity_estimate_v2(vgg19)[0]\n",
        "othernet['zfnet(224x224x1)']=capacity_estimate_v2(zfnet)[0]\n",
        "othernet['alexnet(224x224x1)']=capacity_estimate_v2(alexnet)[0]\n",
        "othernet"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alexnet(224x224x1)': Dimension(204608),\n",
              " 'lenet(28x28x1)': Dimension(7390),\n",
              " 'vgg16(28x28x1)': Dimension(266176),\n",
              " 'vgg19(28x28x1)': Dimension(308416),\n",
              " 'zfnet(224x224x1)': Dimension(431936)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrRjRBSLrBx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR2ISnfD4eof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_params(weights):\n",
        "  \"\"\"Count the total number of scalars composing the weights.\n",
        "  Arguments:\n",
        "      weights: An iterable containing the weights on which to compute params\n",
        "  Returns:\n",
        "      The total number of scalars composing the weights\n",
        "  \"\"\"\n",
        "  return int(\n",
        "      sum(\n",
        "          np.prod(p.shape.as_list())\n",
        "          for p in object_identity.ObjectIdentitySet(weights)))\n",
        "  \n",
        "def print_summary(model, line_length=None, positions=None, print_fn=None):\n",
        "    \"\"\"Prints a summary of a model.\n",
        "    # Arguments\n",
        "        model: Keras model instance.\n",
        "        line_length: Total length of printed lines\n",
        "            (e.g. set this to adapt the display to different\n",
        "            terminal window sizes).\n",
        "        positions: Relative or absolute positions of log elements in each line.\n",
        "            If not provided, defaults to `[.33, .55, .67, 1.]`.\n",
        "        print_fn: Print function to use.\n",
        "            It will be called on each line of the summary.\n",
        "            You can set it to a custom function\n",
        "            in order to capture the string summary.\n",
        "            It defaults to `print` (prints to stdout).\n",
        "    \"\"\"\n",
        "    if print_fn is None:\n",
        "        print_fn = print\n",
        "\n",
        "    if model.__class__.__name__ == 'Sequential':\n",
        "        sequential_like = True\n",
        "    elif not model._is_graph_network:\n",
        "        # We treat subclassed models as a simple sequence of layers,\n",
        "        # for logging purposes.\n",
        "        sequential_like = True\n",
        "    else:\n",
        "        sequential_like = True\n",
        "        nodes_by_depth = model._nodes_by_depth.values()\n",
        "        nodes = []\n",
        "        \n",
        "        if sequential_like:\n",
        "            # search for shared layers\n",
        "            for layer in model.layers:\n",
        "                flag = False\n",
        "                for node in layer._inbound_nodes:\n",
        "                    if node in nodes:\n",
        "                        if flag:\n",
        "                            sequential_like = False\n",
        "                            break\n",
        "                        else:\n",
        "                            flag = True\n",
        "                if not sequential_like:\n",
        "                    break\n",
        "    sequential_like=False\n",
        "\n",
        "    if sequential_like:\n",
        "        line_length = line_length or 65\n",
        "        positions = positions or [.45, .85, 1.]\n",
        "        if positions[-1] <= 1:\n",
        "            positions = [int(line_length * p) for p in positions]\n",
        "        # header names for the different log elements\n",
        "        to_display = ['Layer (type)', 'Output Shape', 'Param #']\n",
        "    else:\n",
        "        line_length = line_length or 98\n",
        "        positions = positions or [.33, .55, .67, 1.]\n",
        "        if positions[-1] <= 1:\n",
        "            positions = [int(line_length * p) for p in positions]\n",
        "        # header names for the different log elements\n",
        "        to_display = ['Layer (type)',\n",
        "                      'Output Shape',\n",
        "                      'Param #',\n",
        "                      'Connected to']\n",
        "        \n",
        "\n",
        "    def print_row(fields, positions):\n",
        "        line = ''\n",
        "        for i in range(len(fields)):\n",
        "            if i > 0:\n",
        "                line = line[:-1] + ' '\n",
        "            line += str(fields[i])\n",
        "            line = line[:positions[i]]\n",
        "            line += ' ' * (positions[i] - len(line))\n",
        "        print_fn(line)\n",
        "\n",
        "    print_fn('Model: \"{}\"'.format(model.name))\n",
        "    print_fn('_' * line_length)\n",
        "    print_row(to_display, positions)\n",
        "    print_fn('=' * line_length)\n",
        "\n",
        "    def print_layer_summary(layer):\n",
        "        try:\n",
        "            output_shape = layer.output_shape\n",
        "        except AttributeError:\n",
        "            output_shape = 'multiple'\n",
        "        name = layer.name\n",
        "        cls_name = layer.__class__.__name__\n",
        "        fields = [name + ' (' + cls_name + ')',\n",
        "                  output_shape, layer.count_params()]\n",
        "        print_row(fields, positions)\n",
        "\n",
        "    def print_layer_summary_with_connections(layer):\n",
        "        \"\"\"Prints a summary for a single layer.\n",
        "        # Arguments\n",
        "            layer: target layer.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            output_shape = layer.output_shape\n",
        "        except AttributeError:\n",
        "            output_shape = 'multiple'\n",
        "        connections = []\n",
        "        for node in layer._inbound_nodes:\n",
        "           \n",
        "            # for i in range(len(node.inbound_layers)):\n",
        "            #     inbound_layer = node.inbound_layers[i].name\n",
        "            #     inbound_node_index = node.node_indices[i]\n",
        "            #     inbound_tensor_index = node.tensor_indices[i]\n",
        "            #     connections.append(inbound_layer +\n",
        "            #                        '[' + str(inbound_node_index) + '][' +\n",
        "            #                        str(inbound_tensor_index) + ']')\n",
        "                \n",
        "            for inbound_layer, node_index, tensor_index, _ in node.iterate_inbound():\n",
        "                connections.append('{}[{}][{}]'.format(inbound_layer.name, node_index,\n",
        "                                               tensor_index))\n",
        "\n",
        "        name = layer.name\n",
        "        cls_name = layer.__class__.__name__\n",
        "        if not connections:\n",
        "            first_connection = ''\n",
        "        else:\n",
        "            first_connection = connections[0]\n",
        "        fields = [name +\n",
        "                  ' (' + cls_name + ')',\n",
        "                  output_shape,\n",
        "                  layer.count_params(),\n",
        "                  first_connection]\n",
        "        print_row(fields, positions)\n",
        "        if len(connections) > 1:\n",
        "            for i in range(1, len(connections)):\n",
        "                fields = ['', '', '', connections[i]]\n",
        "                print_row(fields, positions)\n",
        "\n",
        "    layers = model.layers\n",
        "    for i in range(len(layers)):\n",
        "        if sequential_like:\n",
        "            print_layer_summary(layers[i])\n",
        "        else:\n",
        "            print_layer_summary_with_connections(layers[i])\n",
        "        if i == len(layers) - 1:\n",
        "            print_fn('=' * line_length)\n",
        "        else:\n",
        "            print_fn('_' * line_length)\n",
        "\n",
        "    model._check_trainable_weights_consistency()\n",
        "    if hasattr(model, '_collected_trainable_weights'):\n",
        "        trainable_count = count_params(model._collected_trainable_weights)\n",
        "    else:\n",
        "        trainable_count = count_params(model.trainable_weights)\n",
        "\n",
        "    non_trainable_count = count_params(model.non_trainable_weights)\n",
        "\n",
        "    \n",
        "    print_fn(\n",
        "        'Total params: {:,}'.format(trainable_count + non_trainable_count))\n",
        "    print_fn('Trainable params: {:,}'.format(trainable_count))\n",
        "    print_fn('Non-trainable params: {:,}'.format(non_trainable_count))\n",
        "    print_fn('_' * line_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FPzo7m0_L5l",
        "colab_type": "code",
        "outputId": "d392c526-7479-456d-93cb-320bac631099",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print_summary(resnet1111)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 14, 14, 64)   3200        input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 14, 14, 64)   256         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 14, 14, 64)   0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling2D) (None, 7, 7, 64)     0           activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 7, 7, 64)     36928       max_pooling2d_22[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 7, 7, 64)     256         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 7, 7, 64)     0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 7, 7, 64)     36928       activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_40 (Add)                    (None, 7, 7, 64)     0           max_pooling2d_22[0][0]           \n",
            "                                                                 conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 7, 7, 64)     256         add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 7, 7, 64)     0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 4, 4, 128)    73856       activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 4, 4, 128)    512         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 4, 4, 128)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 4, 4, 128)    8320        add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 4, 4, 128)    147584      activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_41 (Add)                    (None, 4, 4, 128)    0           conv2d_150[0][0]                 \n",
            "                                                                 conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 4, 4, 128)    512         add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 4, 4, 128)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 2, 2, 256)    295168      activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 2, 2, 256)    1024        conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 2, 2, 256)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 2, 2, 256)    33024       add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 2, 2, 256)    590080      activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_42 (Add)                    (None, 2, 2, 256)    0           conv2d_153[0][0]                 \n",
            "                                                                 conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 2, 2, 256)    1024        add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 2, 2, 256)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 1, 1, 512)    1180160     activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 1, 1, 512)    2048        conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 1, 1, 512)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 1, 1, 512)    131584      add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 1, 1, 512)    2359808     activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_43 (Add)                    (None, 1, 1, 512)    0           conv2d_156[0][0]                 \n",
            "                                                                 conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 1, 1, 512)    2048        add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 1, 1, 512)    0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 1, 1, 512)    0           activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_11 (Flatten)            (None, 512)          0           average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_20 (Dense)                (None, 10)           5130        flatten_11[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 4,909,706\n",
            "Trainable params: 4,905,738\n",
            "Non-trainable params: 3,968\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}